{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363cf56b",
   "metadata": {},
   "source": [
    "# Predicting DSAIL-Porini dataset animals\n",
    "!['DSAIL DSA Arusha 2022'](./figures/dsa-arusha-dsail-logo.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e898c3d",
   "metadata": {},
   "source": [
    "The animals are the ones below :\n",
    "!['conservancy animals'](./figures/conservancy-animals.PNG)\n",
    "\n",
    "Below I'll take you through a process of predicting what animal is in what image\n",
    "\n",
    "First, we will use mobilenet model with imagenet weights. The imagenet classes have 3 out of 6 of the DSAIL-Porini classes. [imagenet classes](https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e7f92b",
   "metadata": {
    "papermill": {
     "duration": 0.009771,
     "end_time": "2022-07-06T14:30:14.179167",
     "exception": false,
     "start_time": "2022-07-06T14:30:14.169396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcc596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:14.198852Z",
     "iopub.status.busy": "2022-07-06T14:30:14.198064Z",
     "iopub.status.idle": "2022-07-06T14:30:22.933487Z",
     "shell.execute_reply": "2022-07-06T14:30:22.932535Z"
    },
    "papermill": {
     "duration": 8.748066,
     "end_time": "2022-07-06T14:30:22.936046",
     "exception": false,
     "start_time": "2022-07-06T14:30:14.187980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "#use reducelronplateau and lrscheduling\n",
    "#use transfer learning.\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import io\n",
    "import random\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import models\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 \n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet import ResNet152\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "import PIL\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from IPython import display\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fbaac3",
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide-cell",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "# Taken from https://stackoverflow.com/questions/31517194/how-to-hide-one-specific-cell-input-or-output-in-ipython-notebook\n",
    "tag = HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('div.cell.code_cell.rendered.selected div.input').hide();\n",
    "    } else {\n",
    "        $('div.cell.code_cell.rendered.selected div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "To show/hide this cell's raw code input, click <a href=\"javascript:code_toggle()\">here</a>.''')\n",
    "display(tag)\n",
    "\n",
    "\n",
    "def get_score(preds,trues,score,description,species):\n",
    "    animal = species\n",
    "    predictions = [int(pred==species) for pred in list(preds)]\n",
    "    true_labels = [1 for label in list(trues)]\n",
    "    y_pred,y_act = predictions,true_labels\n",
    "    score = score(y_act, y_pred)\n",
    "    return score\n",
    "def get_scores_and_plot(score,score_desc):\n",
    "    s1 = []\n",
    "    s2 = []\n",
    "    tx1 = []\n",
    "    tx2 = []\n",
    "    \n",
    "    for animal in list(reverse_mapping.values()):\n",
    "        df = df_pretrained[df_pretrained['true']==animal]\n",
    "        df = df[df['pred']!=6]\n",
    "        s1.append(get_score(df['pred'],df['true'],score,score_desc+\"Smaller model on Uncropped data on \",animal))\n",
    "        df = df_small_conv[df_small_conv['true']==animal]\n",
    "        s2.append(get_score(df['pred'],df['true'],score,score_desc+\"Smaller model on Cropped data on \",animal))\n",
    "        df = df_mobilenet[df_mobilenet['true']==animal]\n",
    "        tx1.append(get_score(df['pred'],df['true'],score,score_desc+\"Inception Resnet on Uncropped data on \",animal))\n",
    "        df = df_your_model[df_your_model['true']==animal]\n",
    "        tx2.append(get_score(df['pred'],df['true'],score,score_desc+\"Inception Resnet on Cropped data on \",animal))\n",
    "    \n",
    "    #Graph\n",
    "    # set width of bar\n",
    "    barWidth = 0.2\n",
    "    fig = plt.subplots(figsize =(12, 5))\n",
    "\n",
    "    # set height of bar\n",
    "    small_uncropped = s1\n",
    "    small_cropped = s2\n",
    "    Inception_Resnet_uncropped = tx1\n",
    "    Inception_Resnet_cropped = tx2\n",
    "\n",
    "    # Set position of bar on X axis\n",
    "    br1 = np.arange(len(small_uncropped))\n",
    "    br2 = [x + barWidth for x in br1]\n",
    "    br3 = [x + barWidth for x in br2]\n",
    "    br4 = [x + barWidth for x in br3]\n",
    "\n",
    "    # Make the plot\n",
    "    plt.bar(br1, small_uncropped, color ='r', width = barWidth,\n",
    "            edgecolor ='grey', label ='pretrained')\n",
    "    plt.bar(br2, small_cropped, color ='g', width = barWidth,\n",
    "            edgecolor ='grey', label ='small_conv')\n",
    "    plt.bar(br3, Inception_Resnet_uncropped, color ='b', width = barWidth,\n",
    "            edgecolor ='grey', label ='mobilenet')\n",
    "    plt.bar(br4, Inception_Resnet_cropped, color ='y', width = barWidth,\n",
    "            edgecolor ='grey', label ='your-model')\n",
    "\n",
    "    # Adding Xticks\n",
    "    plt.xlabel('model', fontweight ='bold', fontsize = 15)\n",
    "    plt.ylabel(score_desc, fontweight ='bold', fontsize = 15)\n",
    "    plt.xticks([r + barWidth for r in range(len(small_uncropped))],\n",
    "            ['BUSHBUCK', 'IMPALA', 'MONKEY', 'WARTHOG', 'WATERBUCK','ZEBRA'])\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "print('Imported Custom Functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c5eed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:22.955058Z",
     "iopub.status.busy": "2022-07-06T14:30:22.954752Z",
     "iopub.status.idle": "2022-07-06T14:30:22.960574Z",
     "shell.execute_reply": "2022-07-06T14:30:22.959760Z"
    },
    "papermill": {
     "duration": 0.017415,
     "end_time": "2022-07-06T14:30:22.962447",
     "exception": false,
     "start_time": "2022-07-06T14:30:22.945032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set seed for reproducibility.\n",
    "# set seed\n",
    "seed = 2022\n",
    "\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "seed_everything(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1260121",
   "metadata": {
    "papermill": {
     "duration": 0.008283,
     "end_time": "2022-07-06T14:30:22.979556",
     "exception": false,
     "start_time": "2022-07-06T14:30:22.971273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2 Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d98c8b",
   "metadata": {
    "papermill": {
     "duration": 0.00852,
     "end_time": "2022-07-06T14:30:22.996632",
     "exception": false,
     "start_time": "2022-07-06T14:30:22.988112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get directory names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26dc56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:23.016011Z",
     "iopub.status.busy": "2022-07-06T14:30:23.015191Z",
     "iopub.status.idle": "2022-07-06T14:30:23.020352Z",
     "shell.execute_reply": "2022-07-06T14:30:23.019544Z"
    },
    "papermill": {
     "duration": 0.01686,
     "end_time": "2022-07-06T14:30:23.022374",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.005514",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set directories.\n",
    "base_dir = './data/porinicroppedimages/dataset/'\n",
    "\n",
    "# Directory with our training images\n",
    "train_dir = os.path.join(base_dir, 'train/')\n",
    "\n",
    "print(train_dir)\n",
    "\n",
    "#Directory with test images.\n",
    "test_dir = os.path.join(base_dir, 'test/')\n",
    "print(test_dir)\n",
    "#make sure file path ends with a forward slash."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7bced2",
   "metadata": {
    "papermill": {
     "duration": 0.008419,
     "end_time": "2022-07-06T14:30:23.039863",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.031444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Number of Images in train and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84449325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:23.059147Z",
     "iopub.status.busy": "2022-07-06T14:30:23.058671Z",
     "iopub.status.idle": "2022-07-06T14:30:23.578273Z",
     "shell.execute_reply": "2022-07-06T14:30:23.576831Z"
    },
    "papermill": {
     "duration": 0.532395,
     "end_time": "2022-07-06T14:30:23.581135",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.048740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('total training train images :', len(os.listdir(train_dir ) ))\n",
    "print('total training test images :', len(os.listdir(test_dir ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b7741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:23.600486Z",
     "iopub.status.busy": "2022-07-06T14:30:23.600190Z",
     "iopub.status.idle": "2022-07-06T14:30:23.630478Z",
     "shell.execute_reply": "2022-07-06T14:30:23.628911Z"
    },
    "papermill": {
     "duration": 0.042523,
     "end_time": "2022-07-06T14:30:23.633140",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.590617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get data\n",
    "df_train = pd.read_csv(base_dir + 'train.csv')\n",
    "print(df_train.shape)\n",
    "df_test = pd.read_csv(base_dir + 'test.csv')\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36963329",
   "metadata": {},
   "source": [
    "Before you train the model for prediction, you need to perform data [cleaning](https://www.dataquest.io/blog/machine-learning-preparing-data/) and [preprocessing](https://towardsdatascience.com/data-preprocessing-concepts-fa946d11c825). This is a very important step; your model will not perform well without these steps.\n",
    "\n",
    "![process image](./figures/process-data-science.PNG)\n",
    "\n",
    "\n",
    "#### Description\n",
    "filename -  image name in test or train\n",
    "region_count - count of crop to regions\n",
    "region_shape_attributes - The region in the image where the animal is. Here the dataset has already been autocropped but if you download the [whole dataset](https://data.mendeley.com/datasets/6mhrhn7rxc/6)\n",
    "Device - Camera trap device used to capture the image i.e. 'Raspberry Pi 2', 'Raspberry Pi Zero', 'OpenMV Cam H7'\n",
    "Species - Animal i.e. 'WARTHOG', 'IMPALA', 'WATERBUCK', 'ZEBRA', 'MONKEY', 'BUSHBUCK'\n",
    "Count - animals in image\n",
    "Sex - Is the animal Male, Femal or Can't tell\n",
    "Latitude and Longitude - position of camera trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67ebe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:23.694271Z",
     "iopub.status.busy": "2022-07-06T14:30:23.693740Z",
     "iopub.status.idle": "2022-07-06T14:30:23.699475Z",
     "shell.execute_reply": "2022-07-06T14:30:23.698512Z"
    },
    "papermill": {
     "duration": 0.01815,
     "end_time": "2022-07-06T14:30:23.701816",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.683666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df57d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28145c31",
   "metadata": {
    "papermill": {
     "duration": 0.009215,
     "end_time": "2022-07-06T14:30:23.720124",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.710909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b8d13d",
   "metadata": {},
   "source": [
    "### Animal vs Location\n",
    "- We have 6 animals, Where are they"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d3d11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create the figure\n",
    "fig = plt.figure(figsize =(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.set_title('ALL ANIMALS',fontdict = {'fontsize':20})\n",
    "plt.ylim([-0.392,-0.386])\n",
    "plt.xlim(36.961,36.967)\n",
    "imgplot =  sns.scatterplot(data=df_train,x='Longitude',y='Latitude',hue='Species',hue_order = ['BUSHBUCK','IMPALA','MONKEY','WARTHOG','WATERBUCK','ZEBRA']);\n",
    "plt.legend(loc='lower right')\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.set_title('Conservancy',fontdict = {'fontsize':20})\n",
    "image_ = mpimg.imread('./figures/conservancy.PNG')\n",
    "imgplot = plt.imshow(image_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the figure\n",
    "animal = 'IMPALA'\n",
    "def animal_location(animal):\n",
    "    fig = plt.figure(figsize =(12, 4))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.ylim([-0.392,-0.386])\n",
    "    plt.xlim(36.961,36.967)\n",
    "    ax.set_title(animal,fontdict = {'fontsize':20})\n",
    "    imgplot =  sns.scatterplot(data=df_train[df_train['Species']==animal],x='Longitude',y='Latitude');\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    image_ = mpimg.imread('./figures/conservancy.PNG')\n",
    "    ax.set_title('Conservancy',fontdict = {'fontsize':20})\n",
    "    \n",
    "    imgplot = plt.imshow(image_)\n",
    "    plt.show()\n",
    "animal_location(animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930eb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the figure\n",
    "animal = 'WARTHOG'\n",
    "animal_location(animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914fe6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the figure\n",
    "animal = 'WATERBUCK'\n",
    "animal_location(animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b9d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the figure\n",
    "animal = 'BUSHBUCK'\n",
    "animal_location(animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the figure\n",
    "animal = 'MONKEY'\n",
    "animal_location(animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the figure\n",
    "animal = 'ZEBRA'\n",
    "animal_location(animal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b06e8e",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "Animals move around, location cant be used to predict what animal is where"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fb9198",
   "metadata": {},
   "source": [
    "### Why did we crop the porini images\n",
    "\n",
    "1. Increase visibility of animal (Reduce background)\n",
    "\n",
    "2. Reduce dataset (if unnessarily large) 1.3GB (Single Porini Images) -> 13MB (Single Cropped Porini Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998452ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples = './data/samples/'\n",
    "random_image = random.choice([f for f in os.listdir(samples) if '.jpg' in f])\n",
    "print(random_image)\n",
    "plt.imshow(mpimg.imread(samples+random_image));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99850b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_image)\n",
    "img = mpimg.imread(test_dir+random_image)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd58ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:23.740310Z",
     "iopub.status.busy": "2022-07-06T14:30:23.739537Z",
     "iopub.status.idle": "2022-07-06T14:30:23.751414Z",
     "shell.execute_reply": "2022-07-06T14:30:23.749865Z"
    },
    "papermill": {
     "duration": 0.024375,
     "end_time": "2022-07-06T14:30:23.753642",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.729267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shape of the dataframes ?\n",
    "print('Train labels :',df_train.shape)\n",
    "print('Test labels :',df_test.shape)\n",
    "\n",
    "test_ = df_test.shape[0]*[\"test\"]\n",
    "train_ = df_train.shape[0]*[\"train\"]\n",
    "df_test[\"df\"] = test_\n",
    "df_train[\"df\"] = train_\n",
    "\n",
    "#shape of the dataframes ?\n",
    "print('Train labels :',df_train.shape)\n",
    "print('Test labels :',df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f86b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:23.774538Z",
     "iopub.status.busy": "2022-07-06T14:30:23.773691Z",
     "iopub.status.idle": "2022-07-06T14:30:23.783169Z",
     "shell.execute_reply": "2022-07-06T14:30:23.782323Z"
    },
    "papermill": {
     "duration": 0.022089,
     "end_time": "2022-07-06T14:30:23.785289",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.763200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b414fe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:23.809997Z",
     "iopub.status.busy": "2022-07-06T14:30:23.809163Z",
     "iopub.status.idle": "2022-07-06T14:30:23.822773Z",
     "shell.execute_reply": "2022-07-06T14:30:23.821846Z"
    },
    "papermill": {
     "duration": 0.025661,
     "end_time": "2022-07-06T14:30:23.824777",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.799116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba232326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:23.845255Z",
     "iopub.status.busy": "2022-07-06T14:30:23.844549Z",
     "iopub.status.idle": "2022-07-06T14:30:23.859882Z",
     "shell.execute_reply": "2022-07-06T14:30:23.858834Z"
    },
    "papermill": {
     "duration": 0.02722,
     "end_time": "2022-07-06T14:30:23.861776",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.834556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "df[\"Species_code\"] = ord_enc.fit_transform(df[[\"Species\"]])\n",
    "df.groupby([\"Species\"])['Species_code'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86573f97",
   "metadata": {},
   "source": [
    "Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c019bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:23.882624Z",
     "iopub.status.busy": "2022-07-06T14:30:23.881928Z",
     "iopub.status.idle": "2022-07-06T14:30:23.888541Z",
     "shell.execute_reply": "2022-07-06T14:30:23.887729Z"
    },
    "papermill": {
     "duration": 0.019232,
     "end_time": "2022-07-06T14:30:23.890692",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.871460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df[df['df'] == \"train\"]\n",
    "df_test = df[df['df'] == \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67341372",
   "metadata": {
    "papermill": {
     "duration": 0.009322,
     "end_time": "2022-07-06T14:30:23.909486",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.900164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Sanity Check on split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2afc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:23.930255Z",
     "iopub.status.busy": "2022-07-06T14:30:23.929239Z",
     "iopub.status.idle": "2022-07-06T14:30:25.394435Z",
     "shell.execute_reply": "2022-07-06T14:30:25.392832Z"
    },
    "papermill": {
     "duration": 1.477599,
     "end_time": "2022-07-06T14:30:25.396782",
     "exception": false,
     "start_time": "2022-07-06T14:30:23.919183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num = 0\n",
    "for file in list(df_train.filename):\n",
    "    if file in os.listdir(train_dir):\n",
    "        continue\n",
    "    else:\n",
    "        num +=1\n",
    "if num == 0:\n",
    "    print('Good Split!')\n",
    "else:\n",
    "    print('Error in split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3516bce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:25.418314Z",
     "iopub.status.busy": "2022-07-06T14:30:25.417575Z",
     "iopub.status.idle": "2022-07-06T14:30:25.655750Z",
     "shell.execute_reply": "2022-07-06T14:30:25.654814Z"
    },
    "papermill": {
     "duration": 0.251217,
     "end_time": "2022-07-06T14:30:25.657966",
     "exception": false,
     "start_time": "2022-07-06T14:30:25.406749",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot Class Distribution\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(y = df['Species'], data = df, palette = 'bright',order=df['Species'].value_counts().index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To add Compare your model with pretrained model.\n",
    "reverse_mapping = {\n",
    "\"BUSHBUCK\":0.0,\n",
    "\"IMPALA\":1.0,\n",
    "\"MONKEY\":2.0,\n",
    "\"WARTHOG\":3.0,\n",
    "\"WATERBUCK\":4.0,\n",
    "\"ZEBRA\":5.0,\n",
    "}\n",
    "mapping = {\n",
    "    0.0:\"BUSHBUCK\",\n",
    "    1.0:\"IMPALA\",\n",
    "    2.0:\"MONKEY\",\n",
    "    3.0:\"WARTHOG\",\n",
    "    4.0:\"WATERBUCK\",\n",
    "    5.0:\"ZEBRA\"\n",
    "}\n",
    "print(list(reverse_mapping.values()))\n",
    "print(list(mapping.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e029d46",
   "metadata": {},
   "source": [
    "# First pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c489bfef",
   "metadata": {},
   "source": [
    "### Imagenet labels\n",
    "Imagenet was trained on 1000 classes of animals while porini has 6 classes.\n",
    "As a first step: we obtain a model trained on imagenet and try to predict classes of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656903b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {}\n",
    "\n",
    "for image in os.listdir(test_dir):\n",
    "        x = tf.io.read_file(test_dir+image)\n",
    "        x = tf.io.decode_image(x,channels=3) \n",
    "        x = tf.image.resize(x,[224,224])\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "        abc = model.predict(x)\n",
    "        p = tf.keras.applications.imagenet_utils.decode_predictions(\n",
    "            abc, top=1\n",
    "        )[0]\n",
    "        preds[image] = [image,p[0][1],p[0][2]]\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837eac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc65fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds\n",
    "df = pd.DataFrame.from_dict(preds, orient='index',columns=['Filename', 'class', 'confidence'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f483486",
   "metadata": {},
   "source": [
    "##### save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/pretrained_cropped_predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfccaf61",
   "metadata": {},
   "source": [
    "##### load predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.read_csv('./data/pretrained_cropped_predictions.csv')\n",
    "df = df_preds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5735f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds['confidence'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = df_preds['class'].unique()\n",
    "print(len(animals),animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e62d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ = ['impala','zebra','warthog']\n",
    "in_out = []\n",
    "for animal in list(df_preds['class']):\n",
    "    if animal in in_:\n",
    "        in_out.append('Porini')\n",
    "    else:\n",
    "        in_out.append('Not Porini')\n",
    "df_preds['in'] = in_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607493e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(12, 6))\n",
    "#impala,zebra,warthog --- they sum up to 34\n",
    "#Plot Class Distribution\n",
    "sns.set_style('whitegrid')\n",
    "a = sns.countplot(y = df_preds['class'], data = df_preds,hue='in', palette = 'bright',order=df_preds['class'].value_counts()[:20].index);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = pd.read_csv('./data/newimagenet_class.csv')\n",
    "df_preds_cropped = pd.read_csv('./data/pretrained_cropped_predictions.csv')\n",
    "df_test = pd.read_csv('./data/porinicroppedimages/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f644c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter_dict = {}\n",
    "porini = ['monkey','warthog','waterbuck','impala','bushbuck','zebra']\n",
    "for i in range(converter.shape[0]):\n",
    "    #print(converter.to_dict()['imagenet_class'][i] , converter.to_dict()['new_class'][i])\n",
    "    new = converter.to_dict()['new_class'][i]\n",
    "    if new not in porini:\n",
    "        converter_dict[converter.to_dict()['imagenet_class'][i]] = 'none'\n",
    "    else:\n",
    "        converter_dict[converter.to_dict()['imagenet_class'][i]] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67812bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "preverse_mapping = {\n",
    "\"BUSHBUCK\":0.0,\n",
    "\"IMPALA\":1.0,\n",
    "\"MONKEY\":2.0,\n",
    "\"WARTHOG\":3.0,\n",
    "\"WATERBUCK\":4.0,\n",
    "\"ZEBRA\":5.0,\n",
    "\"NONE\":6.0\n",
    "}\n",
    "preds = list(df_preds_cropped['class'])\n",
    "new_preds = [converter_dict[p] for p in preds]\n",
    "df_preds_cropped['pred_class'] = new_preds\n",
    "df_preds_cropped['pred_class']= df_preds_cropped['pred_class'].str.upper()\n",
    "df_preds_cropped['pred'] = [int(preverse_mapping[p]) for p in list(df_preds_cropped['pred_class'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds_cropped['true_class'] = list(df_test['Species'])\n",
    "df_preds_cropped['true'] = [int(reverse_mapping[p]) for p in list(df_preds_cropped['true_class'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds_cropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad18847",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(y = df_preds_cropped['pred_class'], data = df_preds_cropped, palette = 'bright',order=df_preds_cropped['pred_class'].value_counts().index);\n",
    "plt.title('Predictions of Pretrained model');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08fae1a",
   "metadata": {},
   "source": [
    "### Save predictions for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds_cropped.to_csv('./outputs/pretrained_cropped_predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb33c1",
   "metadata": {},
   "source": [
    "##### some insights\n",
    "- mobilenet predicted 58 classes while porini has 6 classes\n",
    "- only 3 of the classes were available\n",
    "-most predictions were wrong \n",
    "- these aren't the best condition for results.\n",
    "\n",
    "\n",
    "We'll train models and see whether we can obtain better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e311411e",
   "metadata": {},
   "source": [
    "# Let's train some models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a45a63",
   "metadata": {
    "papermill": {
     "duration": 0.009893,
     "end_time": "2022-07-06T14:30:25.678405",
     "exception": false,
     "start_time": "2022-07-06T14:30:25.668512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4 Data Preprocessing \n",
    "(remove faults , size the images, remove nonesense data as seen visually, possible segmentation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db11cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:25.700684Z",
     "iopub.status.busy": "2022-07-06T14:30:25.700354Z",
     "iopub.status.idle": "2022-07-06T14:30:25.708357Z",
     "shell.execute_reply": "2022-07-06T14:30:25.707383Z"
    },
    "papermill": {
     "duration": 0.021995,
     "end_time": "2022-07-06T14:30:25.710459",
     "exception": false,
     "start_time": "2022-07-06T14:30:25.688464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert label to string\n",
    "df_train = df_train.astype({\"Species_code\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f812d4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:25.731719Z",
     "iopub.status.busy": "2022-07-06T14:30:25.730953Z",
     "iopub.status.idle": "2022-07-06T14:30:25.738798Z",
     "shell.execute_reply": "2022-07-06T14:30:25.737553Z"
    },
    "papermill": {
     "duration": 0.021135,
     "end_time": "2022-07-06T14:30:25.741275",
     "exception": false,
     "start_time": "2022-07-06T14:30:25.720140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#split to train and test sets, for tuning, for now.\n",
    "# If you comment out this section during training for inference,\n",
    "# the model will have a better performance.\n",
    "\n",
    "train, val = train_test_split(df_train, test_size = 0.113, random_state = seed)\n",
    "print(train.shape, val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac476d7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:25.763187Z",
     "iopub.status.busy": "2022-07-06T14:30:25.762889Z",
     "iopub.status.idle": "2022-07-06T14:30:25.778189Z",
     "shell.execute_reply": "2022-07-06T14:30:25.777157Z"
    },
    "papermill": {
     "duration": 0.028775,
     "end_time": "2022-07-06T14:30:25.780431",
     "exception": false,
     "start_time": "2022-07-06T14:30:25.751656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e03a7",
   "metadata": {
    "papermill": {
     "duration": 0.009687,
     "end_time": "2022-07-06T14:30:25.800276",
     "exception": false,
     "start_time": "2022-07-06T14:30:25.790589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### What are the image sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee15c58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:25.822113Z",
     "iopub.status.busy": "2022-07-06T14:30:25.821628Z",
     "iopub.status.idle": "2022-07-06T14:30:25.828655Z",
     "shell.execute_reply": "2022-07-06T14:30:25.827679Z"
    },
    "papermill": {
     "duration": 0.020494,
     "end_time": "2022-07-06T14:30:25.831383",
     "exception": false,
     "start_time": "2022-07-06T14:30:25.810889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#median size of images is width=96.0, height=78.0\n",
    "#mean size of images is width=160, height=149\n",
    "size = (128,128)\n",
    "batch_size = 32\n",
    "train_size = train.shape[0]\n",
    "val_size = val.shape[0]\n",
    "\n",
    "#to train on whole data per iteration\n",
    "train_steps_per_epoch = int(train_size/batch_size) #int here used to round off\n",
    "val_steps_per_epoch = int(val_size/batch_size) #int here used to round off\n",
    "\n",
    "print('Batch size : ',batch_size)\n",
    "print('Train size : ',train_size)\n",
    "print('Val size : ',val_size)\n",
    "print('Train steps per epoch : ',train_steps_per_epoch)\n",
    "print('Val steps per epoch : ',val_steps_per_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1ddc3",
   "metadata": {},
   "source": [
    "# 5 Image Feature Engineering and Image Augmentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c8125",
   "metadata": {},
   "source": [
    "#### There are two important points to be aware of in this case:\n",
    "\n",
    "* Data augmentation will run on-device, synchronously with the rest of your layers, and benefit from GPU acceleration.\n",
    "\n",
    "* When you export your model using model.save, the preprocessing layers will be saved along with the rest of your model. If you later deploy this model, it will automatically standardize images (according to the configuration of your layers). This can save you from the effort of having to reimplement that logic server-side.\n",
    "\n",
    "*  Data augmentation is inactive at test time so input images will only be augmented during calls to model.fit (not model.evaluate or model.predict)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94652bf1",
   "metadata": {},
   "source": [
    "* You can augment your data to see how they'll impact the training.\n",
    "*For a start we use non augmented data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483db62e",
   "metadata": {},
   "source": [
    "<a id='another_cell'></a>\n",
    "### Augmentation Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ca11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:25.853660Z",
     "iopub.status.busy": "2022-07-06T14:30:25.852959Z",
     "iopub.status.idle": "2022-07-06T14:30:28.377062Z",
     "shell.execute_reply": "2022-07-06T14:30:28.376051Z"
    },
    "papermill": {
     "duration": 2.537984,
     "end_time": "2022-07-06T14:30:28.379851",
     "exception": false,
     "start_time": "2022-07-06T14:30:25.841867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(   \n",
    "                # rotation_range = 30,\n",
    "                # width_shift_range = 0.2,#\n",
    "                # height_shift_range = 0.2,#\n",
    "                # brightness_range = [0.5,1.5],#\n",
    "                # horizontal_flip = True,\n",
    "                # fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31356365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "                    train,\n",
    "                    directory = train_dir,\n",
    "                    x_col = \"filename\",\n",
    "                    y_col = \"Species_code\",\n",
    "                    target_size = size,\n",
    "                    class_mode = \"categorical\",\n",
    "                    batch_size = batch_size,\n",
    "                    shuffle = True,\n",
    "                    seed = seed,\n",
    "                    interpolation = \"nearest\",\n",
    "                    #validate_filenames=False\n",
    ")\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "                    val,\n",
    "                    directory = train_dir, #valid is from train\n",
    "                    x_col = \"filename\",\n",
    "                    y_col = \"Species_code\",\n",
    "                    target_size = size,\n",
    "                    class_mode = \"categorical\",\n",
    "                    batch_size = batch_size,\n",
    "                    shuffle = True,\n",
    "                    seed = seed,\n",
    "                    interpolation = \"nearest\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423cd66e",
   "metadata": {
    "papermill": {
     "duration": 0.011332,
     "end_time": "2022-07-06T14:30:28.402743",
     "exception": false,
     "start_time": "2022-07-06T14:30:28.391411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualize augmentations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cdff8f",
   "metadata": {
    "papermill": {
     "duration": 0.011159,
     "end_time": "2022-07-06T14:30:28.424921",
     "exception": false,
     "start_time": "2022-07-06T14:30:28.413762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Image before augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e0c3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:28.447383Z",
     "iopub.status.busy": "2022-07-06T14:30:28.447029Z",
     "iopub.status.idle": "2022-07-06T14:30:28.452639Z",
     "shell.execute_reply": "2022-07-06T14:30:28.451811Z"
    },
    "papermill": {
     "duration": 0.018833,
     "end_time": "2022-07-06T14:30:28.454610",
     "exception": false,
     "start_time": "2022-07-06T14:30:28.435777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Random Image\n",
    "rand_image = random.choice(os.listdir(train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24678b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:28.476508Z",
     "iopub.status.busy": "2022-07-06T14:30:28.476218Z",
     "iopub.status.idle": "2022-07-06T14:30:28.701644Z",
     "shell.execute_reply": "2022-07-06T14:30:28.700726Z"
    },
    "papermill": {
     "duration": 0.239054,
     "end_time": "2022-07-06T14:30:28.703829",
     "exception": false,
     "start_time": "2022-07-06T14:30:28.464775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(train_dir,rand_image))\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.grid(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471cc82",
   "metadata": {
    "papermill": {
     "duration": 0.011027,
     "end_time": "2022-07-06T14:30:28.726247",
     "exception": false,
     "start_time": "2022-07-06T14:30:28.715220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### After augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a6e7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:28.750026Z",
     "iopub.status.busy": "2022-07-06T14:30:28.748731Z",
     "iopub.status.idle": "2022-07-06T14:30:30.144736Z",
     "shell.execute_reply": "2022-07-06T14:30:30.143728Z"
    },
    "papermill": {
     "duration": 1.412908,
     "end_time": "2022-07-06T14:30:30.150195",
     "exception": false,
     "start_time": "2022-07-06T14:30:28.737287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "# set the title\n",
    "plt.title('Augmented Images')\n",
    "# load the image\n",
    "img = tf.keras.preprocessing.image.load_img(os.path.join(train_dir,rand_image))\n",
    "# convert to numpy array\n",
    "data = tf.keras.preprocessing.image.img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = np.expand_dims(data, 0)\n",
    "# iterator\n",
    "itr = train_datagen.flow(samples, batch_size = 1)\n",
    "# generate samples and plot\n",
    "for i in range(12):\n",
    "    # define subplot\n",
    "    plt.subplot(4,3,i+1)\n",
    "    # generate batch of images\n",
    "    batch = itr.next()\n",
    "    # convert to unsigned integers for viewing\n",
    "    image = batch[0].astype('uint8')\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(image)\n",
    "    plt.grid(None)\n",
    "# show the figure\n",
    "plt.show()\n",
    "\n",
    "#play around with this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d953168",
   "metadata": {
    "papermill": {
     "duration": 0.013295,
     "end_time": "2022-07-06T14:30:30.235708",
     "exception": false,
     "start_time": "2022-07-06T14:30:30.222413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6 Task to you:\n",
    "#### Add agumentations that you think will improve the model accuracy\n",
    "\n",
    "### you can try them on the   [Augmentation Section](#another_cell)\n",
    "\n",
    "* Activating the contraints in ImageDataGenerator \n",
    "* Color modification\n",
    "* Convolution filters\n",
    "* rotate, rescale, translate\n",
    "* darkening and brightening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bdcc5f",
   "metadata": {
    "papermill": {
     "duration": 0.013134,
     "end_time": "2022-07-06T14:30:30.262237",
     "exception": false,
     "start_time": "2022-07-06T14:30:30.249103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7 Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc72ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=(size[0],size[1],3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af50c8d",
   "metadata": {},
   "source": [
    "#### Select the model you want to use\n",
    "\n",
    "1. for a simple model\n",
    "2. for mobilenet_v2\n",
    "\n",
    "##### if your internet is not as fast as you'd want : pick 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcbd10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = int(input(\"Select model you want to use 1 or 2\"))\n",
    "if select == 1 :\n",
    "    print(\"Selected simple model\") #takes aprroximately 60s per epoch\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(6,activation='softmax'))\n",
    "    name = 'model'\n",
    "\n",
    "elif select == 2 :\n",
    "    print(\"Selected mobilenet\")\n",
    "    model = MobileNetV2(weights = 'imagenet', include_top=False, input_shape=shape)\n",
    "    model.trainable = False\n",
    "    gmaxpool2 = tf.keras.layers.GlobalMaxPooling2D()(model.layers[-1].output)\n",
    "    dense2 = tf.keras.layers.Dense(512, activation='relu')(gmaxpool2)\n",
    "    output2 = tf.keras.layers.Dense(6, activation='softmax')(dense2)\n",
    "    model = tf.keras.Model(inputs=[model.inputs], outputs=output2)\n",
    "    name = 'mobilenet'\n",
    "else:\n",
    "    print(\"Error in selection\")\n",
    "print(\"Saved model will be : \",name,'.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11214e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see whole model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcacaee8",
   "metadata": {},
   "source": [
    "#### Callbacks\n",
    "#### Learning rate scheduler\n",
    "Generally, a large learning rate allows the model to learn faster, at the cost of arriving on a sub-optimal final set of weights. A smaller learning rate may allow the model to learn a more optimal or even globally optimal set of weights but may take significantly longer to train\n",
    "\n",
    "#### Modelcheckpoints\n",
    "ModelCheckpoint callback is used in conjunction with training using model. fit() to save a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eabfe82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:30:30.290997Z",
     "iopub.status.busy": "2022-07-06T14:30:30.290621Z",
     "iopub.status.idle": "2022-07-06T14:30:33.045409Z",
     "shell.execute_reply": "2022-07-06T14:30:33.044434Z"
    },
    "papermill": {
     "duration": 2.772206,
     "end_time": "2022-07-06T14:30:33.048246",
     "exception": false,
     "start_time": "2022-07-06T14:30:30.276040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Add Learning rate scheduler.\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler#set_model\n",
    "# This function keeps the initial learning rate for the first ten epochs\n",
    "# and decreases it exponentially after that.\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "callback_lrs = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "#Early Stopping\n",
    "callback_earlystopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "#Reduce LR on Plateau\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=3, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e02c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_load = time.process_time()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print('Compiled')\n",
    "#Save Best model check points\n",
    "\n",
    "checkpoint_filepath = './'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose = 1\n",
    "    )\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=train_steps_per_epoch, #calculated up to standard. train_size/batch_size\n",
    "    validation_data = val_generator, \n",
    "    verbose = 1,\n",
    "    validation_steps=val_steps_per_epoch,\n",
    "    callbacks = [callback_lrs, reduce_lr,model_checkpoint_callback, callback_earlystopping],\n",
    ")\n",
    "\n",
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "\n",
    "model.save(\"models/\"+name+\".h5\")\n",
    "stop_load = time.process_time()\n",
    "print('Time taken by for loop: ',stop_load-start_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c821250",
   "metadata": {
    "papermill": {
     "duration": 0.898919,
     "end_time": "2022-07-06T14:52:31.502565",
     "exception": false,
     "start_time": "2022-07-06T14:52:30.603646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8 Model Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909499b",
   "metadata": {},
   "source": [
    "Proper training over 100 epochs should have this kind of smooth trend:\n",
    "![image](./figures/training-validation-recall.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab90f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:52:33.364719Z",
     "iopub.status.busy": "2022-07-06T14:52:33.363659Z",
     "iopub.status.idle": "2022-07-06T14:52:33.663326Z",
     "shell.execute_reply": "2022-07-06T14:52:33.662400Z"
    },
    "papermill": {
     "duration": 1.207599,
     "end_time": "2022-07-06T14:52:33.665384",
     "exception": false,
     "start_time": "2022-07-06T14:52:32.457785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(generator = val_generator, steps = val_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded6feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:52:35.525726Z",
     "iopub.status.busy": "2022-07-06T14:52:35.525256Z",
     "iopub.status.idle": "2022-07-06T14:52:35.781115Z",
     "shell.execute_reply": "2022-07-06T14:52:35.780072Z"
    },
    "papermill": {
     "duration": 1.155674,
     "end_time": "2022-07-06T14:52:35.783381",
     "exception": false,
     "start_time": "2022-07-06T14:52:34.627707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759a902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T14:52:37.702278Z",
     "iopub.status.busy": "2022-07-06T14:52:37.701936Z",
     "iopub.status.idle": "2022-07-06T14:52:37.961951Z",
     "shell.execute_reply": "2022-07-06T14:52:37.960990Z"
    },
    "papermill": {
     "duration": 1.21947,
     "end_time": "2022-07-06T14:52:37.964006",
     "exception": false,
     "start_time": "2022-07-06T14:52:36.744536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation Loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.to_csv('models/recall_history.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bec9ab2",
   "metadata": {},
   "source": [
    "### Let's look at a few random predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31333017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(directory,random_image=''):\n",
    "    if len(random_image) == 0 :\n",
    "        random_image = random.choice(os.listdir(directory))\n",
    "    #plotting the image\n",
    "    image_ = mpimg.imread(directory+random_image) \n",
    "    #obtaining the image as an array for prediction\n",
    "    img = Image.open(directory + random_image) \n",
    "    img = img.resize(size)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    prediction = model.predict(img)[0]\n",
    "    \n",
    "    #create the figure\n",
    "    fig = plt.figure(figsize =(12, 4))\n",
    "    #subplot for the image\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    imgplot = plt.imshow(image_)\n",
    "    ax.grid(None)\n",
    "    title = df_test.loc[df_test['filename'] ==random_image].Species.values[0]\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    x = ['bushbuck','impala','monkey','warthog','waterbuck','zebra']\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    imgplot = plt.bar(x,prediction,color=['b','y','g','r','c','k'])\n",
    "    ax.grid(None)\n",
    "    ax.set_title('Confidence')\n",
    "    plt.show()\n",
    "    return random_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f8f444",
   "metadata": {},
   "source": [
    "##### Prediction on uncropped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055b2b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_image = random.choice(os.listdir('./data/samples/'))\n",
    "random_image = predict_single_image('./data/samples/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1239da2",
   "metadata": {},
   "source": [
    "##### Prediction on cropped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad9279",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_single_image('./data/porinicroppedimages/dataset/test/',random_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae82fad",
   "metadata": {},
   "source": [
    "## Compare model to some baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#never forget the slash.\n",
    "test_images = os.listdir(test_dir)\n",
    "\n",
    "#time a piece of code.\n",
    "import time\n",
    "images_test = []\n",
    "preds = {}\n",
    "# load all images\n",
    "start_load = time.process_time()\n",
    "i = 0\n",
    "#Adding multiprocessing.\n",
    "for imgname in test_images:\n",
    "    img = Image.open(test_dir + imgname)\n",
    "    #img = tf.keras.preprocessing.image.load_img(test_dir + img)\n",
    "    img = img.resize(size)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    preds[imgname] = [imgname,model.predict(img).argmax(axis = 1)[0]]\n",
    "    i += 1\n",
    "#print(preds)\n",
    "stop_load = time.process_time()\n",
    "print('Time taken by for loop: ',stop_load-start_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a26e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame.from_dict(preds, orient='index', columns=['filename','pred'])\n",
    "prediction_classes = [mapping[p] for p in list(df_preds['pred'])]\n",
    "df_preds['pred_class'] = prediction_classes\n",
    "df_preds['true_class'] = list(df_test['Species'])\n",
    "true = [int(reverse_mapping[p]) for p in list(df_preds['true_class'])]\n",
    "df_preds['true'] = true \n",
    "df_preds.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'outputs/'+name+'_preds.csv'\n",
    "df_preds.to_csv(file,index=False)\n",
    "print('File saved as : ',file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810155d",
   "metadata": {},
   "source": [
    "### Compare your model with others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981da634",
   "metadata": {},
   "source": [
    "##### Load all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pretrained = pd.read_csv('./outputs/pretrained_cropped_predictions.csv')\n",
    "df_small_conv = pd.read_csv('./inputs/model_preds.csv')\n",
    "df_mobilenet = pd.read_csv('./inputs/mobilenet_preds.csv')\n",
    "df_your_model = pd.read_csv('./'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31718acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pretrained.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2239ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pretrained[(df_pretrained['pred']!=6)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcfd588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#true class for all models should be same.\n",
    "print((list(df_pretrained['true'])==list(df_small_conv['true'])))\n",
    "print((list(df_pretrained['true'])==list(df_mobilenet['true'])))\n",
    "print((list(df_pretrained['true'])==list(df_your_model['true'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d8839",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f5c5cc",
   "metadata": {},
   "source": [
    "##### Accuracy\n",
    "!['accuracy'](./figures/accuracy.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a632d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores_and_plot(accuracy_score,'Accuracy') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c057f",
   "metadata": {},
   "source": [
    "#### F1 Score - how well the model performing on class imbalance\n",
    "\n",
    "F1-score is one of the most important evaluation metrics in machine learning. It elegantly sums up the predictive performance of a model by combining two otherwise competing metrics  precision and recall\n",
    "\n",
    "!['f1 score'](./figures/f1-score.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c3a9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_scores_and_plot(f1_score,'f1_score') #because of class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29400a3d",
   "metadata": {},
   "source": [
    "### try to train a better model than mobilenet or try better visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac844e",
   "metadata": {
    "papermill": {
     "duration": 0.89733,
     "end_time": "2022-07-06T14:52:41.940415",
     "exception": false,
     "start_time": "2022-07-06T14:52:41.043085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "1. [Keras.io TranferLearning and Finetuning](https://keras.io/guides/transfer_learning/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1362.580079,
   "end_time": "2022-07-06T14:52:48.618477",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-06T14:30:06.038398",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
